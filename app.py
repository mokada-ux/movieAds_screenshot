# app.py (å …ç‰¢ãƒ•ãƒ«ãƒªãƒ©ã‚¤ãƒˆç‰ˆ)
import streamlit as st
import os
import tempfile
import subprocess
import base64
import shutil
import time
import traceback
from typing import List, Dict
import whisper

# -------------------------
# è¨­å®š
# -------------------------
st.set_page_config(page_title="å‹•ç”»ã‚·ãƒ¼ãƒ³è§£æãƒ„ãƒ¼ãƒ« (å®‰å®šç‰ˆ)", layout="wide")
UPLOAD_DIR = "temp_uploads"
OUTPUT_DIR = "temp_outputs"
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

# -------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# -------------------------
def log_and_show(err_msg: str):
    """ç”»é¢ã«ã‚¨ãƒ©ãƒ¼ï¼ãƒ­ã‚°ã‚’è¡¨ç¤ºï¼ˆé–‹ç™ºç”¨ï¼‰"""
    st.error(err_msg)

def check_command(cmd_name: str) -> bool:
    """ã‚³ãƒãƒ³ãƒ‰ãŒ PATH ã«ã‚ã‚‹ã‹ç¢ºèª"""
    return shutil.which(cmd_name) is not None

def run_subprocess(cmd: List[str], timeout: int = 60) -> subprocess.CompletedProcess:
    """subprocess ã‚’å®‰å…¨ã«å®Ÿè¡Œã—ã¦çµæœã‚’è¿”ã™ã€‚ä¾‹å¤–ã¯å‘¼ã³å‡ºã—å…ƒã§å‡¦ç†"""
    return subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=timeout)

# -------------------------
# å‹•ç”»æƒ…å ±å–å¾—ï¼ˆffprobe ãŒç„¡ã‘ã‚Œã° ffmpeg ã§ä»£æ›¿ï¼‰
# -------------------------
def get_video_duration(video_path: str) -> float:
    """å‹•ç”»ã®é•·ã•ï¼ˆç§’ï¼‰ã‚’å–å¾—ã™ã‚‹ã€‚ffprobe ãŒç„¡ã‘ã‚Œã° ffmpeg å‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ä»£æ›¿"""
    try:
        if check_command("ffprobe"):
            cmd = [
                "ffprobe", "-v", "error",
                "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1",
                video_path
            ]
            cp = run_subprocess(cmd, timeout=15)
            out = cp.stdout.decode().strip()
            return float(out)
        elif check_command("ffmpeg"):
            # ffmpeg ã® stderr ã« Duration: 00:00:10.00 ã®ã‚ˆã†ã«å‡ºã‚‹ã®ã§ parse
            cmd = ["ffmpeg", "-i", video_path]
            cp = run_subprocess(cmd, timeout=15)
            stderr = cp.stderr.decode(errors="ignore")
            for line in stderr.splitlines():
                if "Duration:" in line:
                    # ä¾‹: Duration: 00:00:10.05, start: 0.000000, bitrate: ...
                    try:
                        part = line.split("Duration:")[1].split(",")[0].strip()
                        h, m, s = part.split(":")
                        sec = float(h) * 3600 + float(m) * 60 + float(s)
                        return sec
                    except Exception:
                        continue
            # æ¡ã‚Œãªã‘ã‚Œã° fallback 0
            return 0.0
        else:
            raise FileNotFoundError("ffmpeg/ffprobe ãŒ PATH ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚packages.txt ã« ffmpeg ã‚’å…¥ã‚Œã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¦ãã ã•ã„ã€‚")
    except subprocess.TimeoutExpired:
        raise RuntimeError("ffprobe/ffmpeg ã®å®Ÿè¡ŒãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
    except Exception as e:
        raise

# -------------------------
# ã‚·ãƒ¼ãƒ³æŠ½å‡ºï¼ˆffmpeg select=scene ã‚’åˆ©ç”¨ï¼‰
# -------------------------
def extract_scenes_with_ffmpeg(video_path: str, threshold: float = 0.3, timeout_per_frame: int = 60) -> List[Dict]:
    """
    ffmpeg ã® select='gt(scene,threshold)' ã‚’ä½¿ã£ã¦ã‚·ãƒ¼ãƒ³åˆ‡ã‚Šå‡ºã—ã‚’è¡Œã†ã€‚
    æˆ»ã‚Šï¼šimage file paths ã®ãƒªã‚¹ãƒˆï¼ˆæ™‚ç³»åˆ—é †ï¼‰ã€‚
    """
    if not check_command("ffmpeg"):
        raise FileNotFoundError("ffmpeg ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚packages.txt ã« ffmpeg ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")

    tmp_dir = tempfile.mkdtemp(prefix="scenes_")
    # ffmpeg filter: select frames where scene score > threshold
    cmd = [
        "ffmpeg",
        "-i", video_path,
        "-vf", f"select='gt(scene,{threshold})'",
        "-vsync", "vfr",
        "-q:v", "3",  # ç”»è³ªèª¿æ•´ï¼ˆ3ï½5ãã‚‰ã„ï¼‰
        os.path.join(tmp_dir, "scene_%04d.jpg")
    ]

    # å®Ÿè¡Œï¼ˆstderr ã‚’æ¨ã¦ãšã«å–å¾—ã—ã¦ãŠãï¼‰
    try:
        cp = run_subprocess(cmd, timeout=300)  # å¤§ãã„å‹•ç”»ãªã‚‰æ™‚é–“ã‹ã‹ã‚‹
    except subprocess.TimeoutExpired:
        raise RuntimeError("ffmpeg ã«ã‚ˆã‚‹ã‚·ãƒ¼ãƒ³æŠ½å‡ºãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")

    if cp.returncode != 0:
        # ffmpeg ãŒå¤±æ•—ã—ãŸç†ç”±ã‚’ stderr ã«ä¿æŒã—ã¦è¿”ã™
        err = cp.stderr.decode(errors="ignore")
        raise RuntimeError(f"ffmpeg ã‚·ãƒ¼ãƒ³æŠ½å‡ºãŒå¤±æ•—ã—ã¾ã—ãŸ: {err[:1000]}")

    # æŠ½å‡ºã•ã‚ŒãŸç”»åƒä¸€è¦§ã‚’å–å¾—
    imgs = sorted([os.path.join(tmp_dir, fn) for fn in os.listdir(tmp_dir) if fn.lower().endswith(".jpg")])
    scenes = []
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‹ã‚‰æ¨å®šæ™‚åˆ»ã¯å‰²ã‚Šå½“ã¦ãªã—ï¼ˆå¾Œã§durationã§å‡ç­‰å‰²ï¼‰
    for idx, img in enumerate(imgs):
        scenes.append({"img_path": img, "index": idx})
    return scenes

# -------------------------
# Whisper èª­ã¿è¾¼ã¿ï¼ˆsmallï¼‰ & transcribeï¼ˆsegmentsï¼‰
# -------------------------
@st.cache_resource
def load_whisper_model():
    return whisper.load_model("small")

def transcribe_video_segments(video_path: str):
    model = load_whisper_model()
    # segments ã‚’å–ã‚ŠãŸã„ã®ã§ verboseãªå½¢å¼ã§å–å¾—
    with st.spinner("Whisper ãŒéŸ³å£°ã‚’è§£æã—ã¦ã„ã¾ã™...ï¼ˆæ™‚é–“ã‹ã‹ã‚Šã¾ã™ï¼‰"):
        result = model.transcribe(video_path, language="ja")
    segments = result.get("segments", [])
    return segments

# -------------------------
# image -> base64 ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–
# -------------------------
@st.cache_data
def image_to_b64(path: str) -> str:
    with open(path, "rb") as f:
        return base64.b64encode(f.read()).decode()

# -------------------------
# ã‚·ãƒ¼ãƒ³ã¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ
# -------------------------
def align_scenes_and_segments(scenes: List[Dict], segments: List[Dict], duration: float) -> List[Dict]:
    """
    scenes: [{"img_path":..., "index":...}, ...]
    segments: whisper ã® segments (start,end,text)
    duration: å‹•ç”»ç·ç§’æ•°ï¼ˆ0 ã®å ´åˆã¯å‡ç­‰å‰²ï¼‰
    """
    # ã¾ãšå„ã‚·ãƒ¼ãƒ³ã« start/end ã®ç§’ã‚’æ¨å®šï¼ˆselectæŠ½å‡ºã¯æ™‚åˆ»ã‚’è¿”ã•ãªã„ãŸã‚ï¼‰
    n = len(scenes)
    if n == 0:
        return []

    # If duration is available, map each scene index to rough start time by equal partition.
    if duration and duration > 0:
        for s in scenes:
            idx = s["index"]
            s["start"] = (idx * duration) / max(1, n)
            s["end"] = ((idx + 1) * duration) / max(1, n)
    else:
        # fallback: start = index, end = index+1 (not ideal)
        for s in scenes:
            idx = s["index"]
            s["start"] = idx
            s["end"] = idx + 1

    # Prepare text list per scene
    for s in scenes:
        s["text_list"] = []

    # Assign segments by midpoint
    for seg in segments:
        seg_mid = (seg.get("start", 0) + seg.get("end", 0)) / 2
        matched = False
        for s in scenes:
            if s["start"] <= seg_mid < s["end"]:
                s["text_list"].append(seg.get("text", "").strip())
                matched = True
                break
        if not matched:
            # if not matched, append to last scene
            scenes[-1]["text_list"].append(seg.get("text", "").strip())

    # Compose final fields
    for s in scenes:
        s["time_str"] = f"{s['start']:.1f}"
        s["text"] = "\n".join([t for t in s["text_list"] if t])

    return scenes

# -------------------------
# TSV æ¨ª3è¡Œ x nåˆ— ç”Ÿæˆ
# -------------------------
def generate_tsv_horizontal_from_scenes(scenes: List[Dict]) -> str:
    time_row = ["æ™‚é–“"]
    image_row = ["ç”»åƒ"]
    text_row = ["ãƒ†ã‚­ã‚¹ãƒˆ"]

    for s in scenes:
        time_row.append(s.get("time_str", ""))
        # base64 formula for Google Sheets =IMAGE("data:image/jpeg;base64,....")
        if s.get("img_path") and os.path.exists(s["img_path"]):
            b64 = image_to_b64(s["img_path"])
            img_formula = f'=IMAGE("data:image/jpeg;base64,{b64}")'
        else:
            img_formula = ""
        image_row.append(img_formula)
        text_row.append(s.get("text",""))

    tsv = "\n".join(["\t".join(time_row), "\t".join(image_row), "\t".join(text_row)])
    return tsv

# -------------------------
# UI: ãƒ¡ã‚¤ãƒ³
# -------------------------
st.title("ğŸ¥ å‹•ç”»â†’ã‚·ãƒ¼ãƒ³æŠ½å‡º & Whisper æ›¸ãèµ·ã“ã—ï¼ˆå®‰å®šç‰ˆï¼‰")

# ç’°å¢ƒè¨ºæ–­ï¼ˆç°¡æ˜“ï¼‰
with st.expander("ç’°å¢ƒãƒã‚§ãƒƒã‚¯ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§è¡¨ç¤ºï¼‰", expanded=False):
    st.write("ffmpeg:", shutil.which("ffmpeg"))
    st.write("ffprobe:", shutil.which("ffprobe"))
    st.write("whisper model cache:", "available" if check_command("python") else "python ok")  # dummy

uploaded = st.file_uploader("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆmp4/mov/aviï¼‰", type=["mp4","mov","avi","mkv","webm"])

if not uploaded:
    st.info("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# Save uploaded to temp file
with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded.name)[1]) as tmpf:
    tmpf.write(uploaded.read())
    video_path = tmpf.name

st.success(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {os.path.basename(video_path)}")

# Main action
if st.button("ğŸš€ è§£æã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆæ™‚é–“ã‹ã‹ã‚Šã¾ã™ï¼‰"):
    # Run entire pipeline in try/except and show traceback in UI to avoid silent Oh no
    try:
        start_ts = time.time()

        # 1) duration
        try:
            duration = get_video_duration(video_path)
            st.info(f"å‹•ç”»é•·ã•: {duration:.1f} ç§’")
        except Exception as e:
            st.warning(f"å‹•ç”»é•·ã•ã®å–å¾—ã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            duration = 0.0

        # 2) scene extraction
        try:
            with st.spinner("ã‚·ãƒ¼ãƒ³æŠ½å‡ºï¼ˆffmpegï¼‰ä¸­..."):
                scenes_raw = extract_scenes_with_ffmpeg(video_path, threshold=0.3)
            if not scenes_raw:
                st.warning("ã‚·ãƒ¼ãƒ³ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚å‹•ç”»å…¨ä½“ã‚’1ã‚·ãƒ¼ãƒ³ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚")
                scenes_raw = [{"img_path": None, "index": 0}]
        except Exception as e:
            tb = traceback.format_exc()
            log_and_show("ã‚·ãƒ¼ãƒ³æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°ã¯ä¸‹è¨˜ã€‚")
            st.code(tb)
            raise

        # 3) transcribe
        try:
            segments = transcribe_video_segments(video_path)
            st.success(f"æ›¸ãèµ·ã“ã—å®Œäº†ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(segments)})")
        except Exception as e:
            tb = traceback.format_exc()
            log_and_show("Whisper ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°ã¯ä¸‹è¨˜ã€‚")
            st.code(tb)
            raise

        # 4) align
        try:
            scenes = align_scenes_and_segments(scenes_raw, segments, duration)
        except Exception as e:
            tb = traceback.format_exc()
            log_and_show("ã‚·ãƒ¼ãƒ³ã¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®çµåˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°ã¯ä¸‹è¨˜ã€‚")
            st.code(tb)
            raise

        # 5) UI è¡¨ç¤ºï¼ˆæ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚«ãƒ¼ãƒ‰ï¼‰
        st.subheader("ğŸ” ã‚·ãƒ¼ãƒ³ä¸€è¦§")
        # build HTML cards
        html = '<div style="display:flex; gap:16px; overflow-x:auto; padding:8px;">'
        for s in scenes:
            img_html = ""
            if s.get("img_path") and os.path.exists(s["img_path"]):
                try:
                    b64 = image_to_b64(s["img_path"])
                    img_html = f'<img src="data:image/jpeg;base64,{b64}" style="width:220px; border-radius:8px; display:block;">'
                except Exception:
                    img_html = '<div style="width:220px;height:140px;background:#eee;display:flex;align-items:center;justify-content:center;">No Image</div>'
            else:
                img_html = '<div style="width:220px;height:140px;background:#eee;display:flex;align-items:center;justify-content:center;">No Image</div>'

            t = s.get("time_str","")
            tx = s.get("text","")
            # escape simple characters to avoid HTML break (replace & < >)
            tx_safe = (tx.replace("&","&amp;").replace("<","&lt;").replace(">","&gt;"))
            html += f'''
            <div style="min-width:240px;padding:10px;background:#fff;border-radius:8px;box-shadow:0 6px 18px rgba(0,0,0,0.06);">
                {img_html}
                <div style="margin-top:8px;font-size:13px;color:#333;"><b>â± {t} s</b></div>
                <div style="margin-top:6px;font-size:13px;color:#222;white-space:pre-wrap;">{tx_safe}</div>
            </div>
            '''
        html += "</div>"
        st.markdown(html, unsafe_allow_html=True)

        # 6) TSV å‡ºåŠ›ï¼ˆæ¨ª3è¡Œ x n åˆ—ï¼‰
        st.subheader("ğŸ“‹ Google ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆç”¨ TSVï¼ˆæ¨ª3è¡Œ Ã— ã‚·ãƒ¼ãƒ³æ•°åˆ—ï¼‰")
        if st.button("TSVã‚’ç”Ÿæˆã—ã¦è¡¨ç¤º"):
            try:
                tsv = generate_tsv_horizontal_from_scenes(scenes)
                st.code(tsv, language="text")
                st.success("TSV ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚")
            except Exception:
                st.error("TSV ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                st.code(traceback.format_exc())

        elapsed = time.time() - start_ts
        st.info(f"å‡¦ç†å®Œäº†ï¼ˆæ‰€è¦æ™‚é–“: {elapsed:.1f} ç§’ï¼‰")

    except Exception as e_main:
        # æœ€çµ‚ catchï¼šç”»é¢ã« traceback ã‚’å¿…ãšå‡ºã™ï¼ˆStreamlit Cloud ã® Oh no ã‚’å›é¿ï¼‰
        tb_all = traceback.format_exc()
        st.error("è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ä¸‹è¨˜ã®è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.code(tb_all)

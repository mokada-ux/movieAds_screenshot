import streamlit as st
import os
import cv2
import whisper
import shutil
import zipfile
import datetime
from scenedetect import VideoManager, SceneManager
from scenedetect.detectors import ContentDetector

# --- è¨­å®š ---
UPLOAD_DIR = "temp_uploads"
OUTPUT_DIR = "temp_outputs"
# ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ä½œæˆ
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

# --- é–¢æ•°: æ™‚é–“è¡¨ç¤º ---
def format_time(seconds):
    return str(datetime.timedelta(seconds=int(seconds)))

# --- é–¢æ•°: ãƒ•ã‚©ãƒ«ãƒ€ãƒªã‚»ãƒƒãƒˆ ---
def clear_output_folder():
    if os.path.exists(OUTPUT_DIR):
        shutil.rmtree(OUTPUT_DIR)
    os.makedirs(OUTPUT_DIR, exist_ok=True)

# --- é–¢æ•°: ã‚·ãƒ¼ãƒ³æŠ½å‡º ---
def extract_scenes(video_path):
    video_manager = VideoManager([video_path])
    scene_manager = SceneManager()
    # threshold=27.0 ã¯æ„Ÿåº¦ã®æ¨™æº–å€¤ã€‚å‹•ããŒå°‘ãªã„å‹•ç”»ãªã‚‰ä¸‹ã’ã¦ãã ã•ã„ã€‚
    scene_manager.add_detector(ContentDetector(threshold=27.0))
    
    video_manager.start()
    scene_manager.detect_scenes(frame_source=video_manager)
    scene_list = scene_manager.get_scene_list()
    
    cap = cv2.VideoCapture(video_path)
    scenes_data = []

    progress_bar = st.progress(0, text="ã‚·ãƒ¼ãƒ³æ¤œå‡ºä¸­...")
    total_scenes = len(scene_list)
    
    for i, scene in enumerate(scene_list):
        start_time = scene[0].get_seconds()
        
        cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)
        ret, frame = cap.read()
        
        if ret:
            img_filename = f"scene_{i:03d}_{int(start_time)}s.jpg"
            img_path = os.path.join(OUTPUT_DIR, img_filename)
            cv2.imwrite(img_path, frame)
            
            scenes_data.append({
                "time_str": format_time(start_time),
                "seconds": start_time,
                "img_path": img_path,
                "filename": img_filename
            })
        
        if total_scenes > 0:
            progress_bar.progress(min((i + 1) / total_scenes, 1.0))

    cap.release()
    progress_bar.empty()
    return scenes_data

# --- é–¢æ•°: éŸ³å£°æ›¸ãèµ·ã“ã— ---
@st.cache_resource
def load_whisper_model():
    return whisper.load_model("base") # ç²¾åº¦é‡è¦–ãªã‚‰ "small" ã‚„ "medium" ã«å¤‰æ›´

def transcribe_audio(video_path):
    model = load_whisper_model()
    # st.spinner ã§å‡¦ç†ä¸­ã‚’è¡¨ç¤º
    with st.spinner("AIãŒéŸ³å£°ã‚’è§£æã—ã¦ã„ã¾ã™... (å‹•ç”»ã®é•·ã•ã«ã‚ˆã‚Šæ•°åˆ†ã‹ã‹ã‚Šã¾ã™)"):
        result = model.transcribe(video_path)
    return result["segments"]

# --- é–¢æ•°: ZIPä½œæˆ ---
def create_zip(file_paths):
    zip_path = os.path.join(OUTPUT_DIR, "scenes.zip")
    with zipfile.ZipFile(zip_path, 'w') as zipf:
        for file in file_paths:
            zipf.write(file, os.path.basename(file))
    return zip_path

# ==========================================
# ãƒ¡ã‚¤ãƒ³UI (Streamlit)
# ==========================================
st.set_page_config(page_title="å‹•ç”»è§£æã‚¢ãƒ—ãƒª", layout="wide")

st.title("ğŸ¥ å‹•ç”»ã‚·ãƒ¼ãƒ³ & å­—å¹•æŠ½å‡ºãƒ„ãƒ¼ãƒ«")
st.markdown("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ã™ã‚‹ã ã‘ã§ã€Œ**å ´é¢å†™çœŸ**ã€ã¨ã€Œ**æ–‡å­—èµ·ã“ã—**ã€ã‚’ä¸€æ‹¬ç”Ÿæˆã—ã¾ã™ã€‚")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("è¨­å®š")
    enable_scene = st.checkbox("ã‚·ãƒ¼ãƒ³ç”»åƒã‚’æŠ½å‡ºã™ã‚‹", value=True)
    enable_text = st.checkbox("éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã™ã‚‹", value=True)
    st.divider()
    st.info("â€» FFmpegãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")

uploaded_file = st.file_uploader("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp4", "mov", "avi", "mkv"])

if uploaded_file is not None:
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    video_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
    with open(video_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    st.success(f"èª­ã¿è¾¼ã¿å®Œäº†: {uploaded_file.name}")

    if st.button("ğŸš€ è§£æã‚¹ã‚¿ãƒ¼ãƒˆ", type="primary"):
        clear_output_folder()
        
        # 1. ã‚·ãƒ¼ãƒ³æŠ½å‡º
        scenes = []
        if enable_scene:
            st.subheader("ğŸ“¸ æ¤œå‡ºã•ã‚ŒãŸã‚·ãƒ¼ãƒ³")
            scenes = extract_scenes(video_path)
            
            if scenes:
                # ã‚®ãƒ£ãƒ©ãƒªãƒ¼è¡¨ç¤º
                cols = st.columns(4)
                img_paths = []
                for i, scene in enumerate(scenes):
                    with cols[i % 4]:
                        st.image(scene["img_path"], caption=scene["time_str"])
                    img_paths.append(scene["img_path"])
                
                # ZIPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                zip_path = create_zip(img_paths)
                with open(zip_path, "rb") as fp:
                    st.download_button(
                        label="ğŸ“¥ å…¨ç”»åƒã‚’ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=fp,
                        file_name="scene_images.zip",
                        mime="application/zip"
                    )
            else:
                st.warning("ã‚·ãƒ¼ãƒ³ã®å¤‰åŒ–ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        st.divider()

        # 2. æ–‡å­—èµ·ã“ã—
        if enable_text:
            st.subheader("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ")
            segments = transcribe_audio(video_path)
            
            full_text = ""
            for segment in segments:
                line = f"[{format_time(segment['start'])}] {segment['text']}\n"
                full_text += line
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢è¡¨ç¤º
            st.text_area("æ›¸ãèµ·ã“ã—å†…å®¹", full_text, height=300)
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            st.download_button(
                label="ğŸ“¥ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«(.txt)ã§ä¿å­˜",
                data=full_text,
                file_name="transcription.txt",
                mime="text/plain"
            )
# app.py (ãƒ•ãƒ«ãƒªãƒ©ã‚¤ãƒˆ)
import os
import io
import math
import shutil
import zipfile
import base64
import tempfile
from typing import List, Dict, Tuple

import streamlit as st
from PIL import Image
import cv2
import whisper
from scenedetect import VideoManager, SceneManager
from scenedetect.detectors import ContentDetector

# --------------------
# è¨­å®š
# --------------------
UPLOAD_DIR = "temp_uploads"
OUTPUT_DIR = "temp_outputs"
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

st.set_page_config(page_title="å‹•ç”»è§£æ Pro â€” Stable UI", layout="wide")

# --------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# --------------------
def format_time(seconds: float) -> str:
    s = int(seconds)
    return f"{s//60:02}:{s%60:02}"

def clear_output_folder():
    if os.path.exists(OUTPUT_DIR):
        shutil.rmtree(OUTPUT_DIR)
    os.makedirs(OUTPUT_DIR, exist_ok=True)

# --------------------
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥: base64 å¤‰æ›ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å˜ä½ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
# --------------------
@st.cache_data(show_spinner=False)
def load_image_b64(path: str) -> str:
    with open(path, "rb") as f:
        return base64.b64encode(f.read()).decode()

# --------------------
# Whisper ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
# --------------------
@st.cache_resource(show_spinner=False)
def load_whisper_model(model_size: str = "small"):
    # model_size: "tiny", "small", "medium", "large" ãªã©
    return whisper.load_model(model_size)

# --------------------
# ã‚·ãƒ¼ãƒ³æŠ½å‡ºï¼ˆSceneDetect -> fallback frame-diffï¼‰
# --------------------
def extract_scenes_with_scenedetect(video_path: str, threshold: float = 27.0) -> List[Dict]:
    try:
        video_manager = VideoManager([video_path])
        scene_manager = SceneManager()
        scene_manager.add_detector(ContentDetector(threshold=threshold))
        video_manager.start()
        scene_manager.detect_scenes(frame_source=video_manager)
        scene_list = scene_manager.get_scene_list()
        # video_manager.release()  # VideoManager deprec warning; cap.release used below
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
        frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0
        duration = frame_count / fps if fps else 0
        scenes = []
        # é¦–ã‚·ãƒ¼ãƒ³è£œæ­£
        if not scene_list or scene_list[0][0].get_seconds() > 1.0:
            scenes.append({"start": 0.0, "end": scene_list[0][0].get_seconds() if scene_list else duration})
        for s in scene_list:
            scenes.append({"start": s[0].get_seconds(), "end": s[1].get_seconds()})
        cap.release()
        return scenes
    except Exception as e:
        st.warning(f"SceneDetect ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆfallback ã‚’å®Ÿè¡Œã—ã¾ã™ï¼‰: {e}")
        return []

def fallback_extract_scenes_by_diff(video_path: str, threshold: float = 30.0, min_scene_len: float = 0.8) -> List[Dict]:
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return []
    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
    last_gray = None
    frame_idx = 0
    start_time = 0.0
    scenes = []
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        if last_gray is not None:
            diff = cv2.absdiff(gray, last_gray)
            score = float(diff.mean())
            if score > threshold:
                end_time = frame_idx / fps
                if end_time - start_time >= min_scene_len:
                    scenes.append({"start": start_time, "end": end_time})
                start_time = end_time
        last_gray = gray
        frame_idx += 1
    # æœ€å¾Œã®ã‚·ãƒ¼ãƒ³ã‚’åŠ ãˆã‚‹
    total_duration = (frame_idx / fps) if fps else 0
    if total_duration - start_time >= 0.1:
        scenes.append({"start": start_time, "end": total_duration})
    cap.release()
    return scenes

def extract_scenes(video_path: str, threshold: float = 27.0) -> List[Dict]:
    scenes = extract_scenes_with_scenedetect(video_path, threshold=threshold)
    if not scenes:
        scenes = fallback_extract_scenes_by_diff(video_path, threshold=threshold)
    # ensure at least one scene
    if not scenes:
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
        frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0
        duration = frame_count / fps if fps else 0
        scenes = [{"start": 0.0, "end": duration}]
        cap.release()
    # attach time_str placeholders
    for sc in scenes:
        sc["time_str"] = format_time(sc["start"])
        sc["img"] = None
        sc["text"] = ""
    return scenes

# --------------------
# ã‚¹ã‚¯ã‚·ãƒ§å–å¾—ï¼ˆã‚·ãƒ¼ãƒ³ä¸­ç‚¹ï¼‰
# --------------------
def capture_frame(video_path: str, time_sec: float) -> Image.Image | None:
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return None
    cap.set(cv2.CAP_PROP_POS_MSEC, int(time_sec * 1000))
    ret, frame = cap.read()
    cap.release()
    if not ret:
        return None
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    return Image.fromarray(frame)

# --------------------
# Whisper æ›¸ãèµ·ã“ã—
# --------------------
def transcribe_video(video_path: str, model_size: str = "small", language: str = "ja"):
    model = load_whisper_model(model_size)
    # Whisper ã® transcribe ã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ¸¡ã›ã‚‹
    result = model.transcribe(video_path, language=language)
    return result.get("segments", [])

# --------------------
# ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ -> ã‚·ãƒ¼ãƒ³ ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆä¸­ç‚¹ï¼‰
# --------------------
def align_scenes_and_segments(scenes: List[Dict], segments: List[Dict]) -> List[Dict]:
    for sc in scenes:
        sc["text_list"] = []
    for seg in segments:
        seg_mid = (seg["start"] + seg["end"]) / 2
        matched = False
        for sc in scenes:
            if sc["start"] <= seg_mid < sc["end"]:
                sc["text_list"].append(seg.get("text", "").strip())
                matched = True
                break
        if not matched and scenes:
            scenes[-1]["text_list"].append(seg.get("text", "").strip())
    for sc in scenes:
        sc["text"] = "\n".join([t for t in sc.get("text_list", []) if t])
    return scenes

# --------------------
# UI: CSS
# --------------------
st.markdown(
    """
    <style>
    .scene-container { display:flex; gap:18px; overflow-x:auto; padding:12px 8px 20px 8px; }
    .scene-card { min-width:300px; max-width:320px; background: #fff; border-radius:12px; padding:12px; box-shadow:0 6px 18px rgba(0,0,0,0.08); }
    .scene-img { width:100%; height:auto; border-radius:8px; display:block; }
    .scene-meta { font-size:13px; color:#555; margin-top:8px; }
    .scene-text { margin-top:8px; white-space:pre-wrap; font-size:14px; line-height:1.5; color:#222; max-height:220px; overflow:auto; }
    .controls { display:flex; gap:8px; align-items:center; }
    </style>
    """,
    unsafe_allow_html=True,
)

# --------------------
# Sidebar: è¨­å®š
# --------------------
st.sidebar.header("è§£æè¨­å®š")
model_choice = st.sidebar.selectbox("Whisper model", options=["small", "medium"], index=0,
                                    help="small:å®‰å®š / medium:ã‚ˆã‚Šé«˜ç²¾åº¦ï¼ˆé‡ã„ï¼‰")
threshold = st.sidebar.slider("ã‚·ãƒ¼ãƒ³æ¤œå‡ºã—ãã„å€¤ (diff/ContentDetector)", 15, 60, 27)
max_minutes = st.sidebar.number_input("æœ€å¤§è¨±å¯å‹•ç”»æ™‚é–“ï¼ˆåˆ†ï¼‰", min_value=1, max_value=60, value=20)
allow_zip = st.sidebar.checkbox("ç”»åƒã‚’ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã«ã™ã‚‹", value=True)

st.title("ğŸï¸ å‹•ç”»ã‚·ãƒ¼ãƒ³æŠ½å‡º + é«˜ç²¾åº¦æ–‡å­—èµ·ã“ã— (ãƒ­ãƒ¼ã‚«ãƒ«Whisper)")
st.caption("ç”»åƒã¯æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«è¡¨ç¤ºã€‚ç”»åƒã®ä¸‹ã«ã‚·ãƒ¼ãƒ³ã”ã¨ã®æ›¸ãèµ·ã“ã—ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

# --------------------
# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# --------------------
uploaded = st.file_uploader("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆ.mp4/.mov ç­‰ï¼‰", type=["mp4", "mov", "avi", "mkv"])
if not uploaded:
    st.info("ã¾ãšã¯å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ä¸€æ™‚ä¿å­˜ï¼ˆç¢ºå®Ÿã«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒå¿…è¦ï¼‰
with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded.name)[1]) as tmpf:
    tmpf.write(uploaded.getbuffer())
    video_path = tmpf.name

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º / é•·ã•ãƒã‚§ãƒƒã‚¯ï¼ˆé•·ã™ãã‚‹ã¨å‡¦ç†ãŒé‡ã„ï¼‰
try:
    cap_check = cv2.VideoCapture(video_path)
    fps_check = cap_check.get(cv2.CAP_PROP_FPS) or 30.0
    frames_check = cap_check.get(cv2.CAP_PROP_FRAME_COUNT) or 0
    duration_sec = frames_check / fps_check if fps_check else 0
    cap_check.release()
except Exception:
    duration_sec = 0

if duration_sec and duration_sec > max_minutes * 60:
    st.warning(f"å‹•ç”»ãŒ {max_minutes} åˆ†ã‚’è¶…ãˆã¦ã„ã¾ã™ï¼ˆ{math.ceil(duration_sec/60)} åˆ†ï¼‰ã€‚è§£æã‚’ç¶šã‘ã¾ã™ã‹ï¼Ÿ")
    if not st.button("ç¶šè¡Œã™ã‚‹ï¼ˆè‡ªå·±è²¬ä»»ï¼‰"):
        st.stop()

# --------------------
# å®Ÿè¡Œãƒœã‚¿ãƒ³
# --------------------
if st.button("ğŸš€ è§£æã‚¹ã‚¿ãƒ¼ãƒˆ", type="primary"):
    clear_output_folder()
    st.info("â‘  ã‚·ãƒ¼ãƒ³æŠ½å‡ºã‚’è¡Œã„ã¾ã™...")
    with st.spinner("ã‚·ãƒ¼ãƒ³æŠ½å‡ºä¸­..."):
        scenes = extract_scenes(video_path, threshold=threshold)
        if not scenes:
            # fallback
            scenes = fallback_extract_scenes_by_diff(video_path, threshold=threshold)
        # ensure at least one
        if not scenes:
            st.error("ã‚·ãƒ¼ãƒ³æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.stop()

    st.success(f"{len(scenes)} ã‚·ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")

    # ã‚­ãƒ£ãƒ—ãƒãƒ£ç”»åƒã‚’ä½œã‚‹
    st.info("â‘¡ ã‚·ãƒ¼ãƒ³ç”»åƒã‚’ä½œã‚Šã¾ã™...")
    for i, sc in enumerate(scenes):
        mid = (sc["start"] + sc["end"]) / 2
        img = capture_frame(video_path, mid)
        if img:
            out_path = os.path.join(OUTPUT_DIR, f"scene_{i:03d}.jpg")
            img.save(out_path, format="JPEG", quality=80)
            sc["img"] = out_path
        else:
            sc["img"] = None

    st.success("ç”»åƒä½œæˆå®Œäº†ã€‚")

    # Whisper æ›¸ãèµ·ã“ã—
    st.info("â‘¢ Whisper ã§éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ã‚’è¡Œã„ã¾ã™...")
    try:
        segments = transcribe_video(video_path, model_size=model_choice, language="ja")
    except Exception as e:
        st.error(f"Whisper ã®å®Ÿè¡Œã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

    st.success(f"æ›¸ãèµ·ã“ã—å®Œäº†ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(segments)}ï¼‰")

    # ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ
    scenes = align_scenes_and_segments(scenes, segments)

    # --------------------
    # ã‚®ãƒ£ãƒ©ãƒªãƒ¼è¡¨ç¤ºï¼ˆæ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ï¼‰
    # --------------------
    st.subheader("ğŸ” ã‚·ãƒ¼ãƒ³ä¸€è¦§ï¼ˆæ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ï¼‰")
    html = '<div class="scene-container">'
    for idx, sc in enumerate(scenes):
        img_b64 = ""
        if sc.get("img") and os.path.exists(sc["img"]):
            img_b64 = load_image_b64(sc["img"])
            text_html = st.markdown  # placeholder to satisfy linter (unused)
            text_escaped = sc.get("text", "").replace("\n", "<br>")
            html += f"""
            <div class="scene-card">
                <img src="data:image/jpeg;base64,{img_b64}" class="scene-img" />
                <div class="scene-meta"><b>Scene {idx+1}</b> &nbsp; {sc['time_str']}ã€œ</div>
                <div class="scene-text">{text_escaped}</div>
            </div>
            """
        else:
            html += f"""
            <div class="scene-card">
                <div style="height:160px; display:flex;align-items:center;justify-content:center;background:#f6f6f6;border-radius:8px;">No Image</div>
                <div class="scene-meta"><b>Scene {idx+1}</b> &nbsp; {sc['time_str']}ã€œ</div>
                <div class="scene-text">{sc.get('text','')}</div>
            </div>
            """
    html += "</div>"
    st.markdown(html, unsafe_allow_html=True)

    # --------------------
    # TSV ã¨ ZIP ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    # --------------------
    st.subheader("ğŸ“¥ å‡ºåŠ›ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    tsv_text = "\t".join([ (s.get("text","").replace("\n", " ") if s.get("text") else "") for s in scenes ])
    st.code(tsv_text, language="text")

    if allow_zip:
        # ç”»åƒã‚’ZIPã«ã¾ã¨ã‚ã¦ãƒã‚¤ãƒˆé…åˆ—ã«ã™ã‚‹
        zip_buf = io.BytesIO()
        with zipfile.ZipFile(zip_buf, "w", zipfile.ZIP_DEFLATED) as zf:
            for s in scenes:
                if s.get("img") and os.path.exists(s["img"]):
                    zf.write(s["img"], arcname=os.path.basename(s["img"]))
        zip_buf.seek(0)
        st.download_button("ç”»åƒã‚’ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", zip_buf, file_name="scenes_images.zip", mime="application/zip")

    # TSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    tsv_bytes = tsv_text.encode("utf-8")
    st.download_button("TSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæ¨ªä¸¦ã³ï¼‰", tsv_bytes, file_name="scenes_texts.tsv", mime="text/tab-separated-values")

    st.success("å®Œäº†ï¼å¿…è¦ãªã‚‰æ¬¡ã«ä»¥ä¸‹ã‚’ã‚„ã‚Šã¾ã™:\nãƒ»ã‚«ãƒ¼ãƒ‰ã‚¯ãƒªãƒƒã‚¯ã§æ‹¡å¤§è¡¨ç¤º\nãƒ»ç”»åƒã®ãƒˆãƒªãƒŸãƒ³ã‚°/è£œæ­£\nãƒ»Whisperã‚’APIåŒ–ã—ã¦é«˜é€ŸåŒ–ï¼ˆæœ‰æ–™ï¼‰")
